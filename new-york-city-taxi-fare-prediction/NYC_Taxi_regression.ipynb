{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jFYUiH6Bma8j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Rajesh\\Anaconda3\\envs\\tfmllib\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUgW1O44ma8q"
   },
   "outputs": [],
   "source": [
    "#tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqkn34aZma80"
   },
   "source": [
    "Setup varaibles that are required for input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSwY8plrma81"
   },
   "outputs": [],
   "source": [
    "FILE_NAME = 'train.csv'\n",
    "CSV_COLUMNS = 'key,fare_amount,pickupdate,pickuplon,pickuplat,dropofflon,dropofflat,passengers'.split(',')\n",
    "DATE_COLUMNS = 'year,month,day,day_of_week,hours'.split(',')\n",
    "DISTANCE_COLUMN = 'euclid_distance'\n",
    "LAT_DISTANCE = 'latitude_diff'\n",
    "LON_DISTANCE = 'longitude_diff'\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [['nokey'], [0.0], [b'2001-01-01 00:00:01 UTC'], [-74.0], [40.0], [-74.0], [40.7], [1.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWJ1Z0FVma8t"
   },
   "source": [
    "Preview data as Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "Nxv5mDIama8t",
    "outputId": "a9ecf6ed-8ffc-44c2-a10a-a2ac8d74d498"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n",
       "1    2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n",
       "2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
       "3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n",
       "4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "\n",
       "   passenger_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset = pd.read_csv(FILE_NAME, nrows=100)\n",
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "qi0HVCXWma8x",
    "outputId": "f917604c-3279-4316-f5a0-6ef40913050b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                   object\n",
       "fare_amount          float64\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNz8FiUhma84"
   },
   "source": [
    "Function that will convert datetime into Year, Month, Day, Weekday and Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWTJXPs-ma85"
   },
   "outputs": [],
   "source": [
    "def pd_date_time(date_time):\n",
    "    pd_date_time = pd.to_datetime(date_time.decode('utf-8'))\n",
    "    pd_date_time = [pd_date_time.year, pd_date_time.month, \n",
    "                    pd_date_time.day, pd_date_time.weekday(), \n",
    "                    pd_date_time.hour]\n",
    "    return pd_date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_92U1C5lma87",
    "outputId": "338a495b-1222-4810-a409-812ec282773a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2001, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(pd_date_time(b'2001-01-01 00:00:01 UTC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GZI6oEYma8_"
   },
   "source": [
    "Create feature engineering function that will be used in the input and serving input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wO91CCdema8_"
   },
   "outputs": [],
   "source": [
    "def feature_engg(features):\n",
    "    lat1 = features['pickuplat']\n",
    "    lat2 = features['dropofflat']\n",
    "    lat_diff = (lat1 - lat2)\n",
    "    lon1 = features['pickuplon']\n",
    "    lon2 = features['dropofflon']\n",
    "    lon_diff = lon1 - lon2\n",
    "    dist = tf.sqrt((lat_diff * lat_diff) + (lon_diff * lon_diff))\n",
    "    features[LAT_DISTANCE] = lat_diff\n",
    "    features[LON_DISTANCE] = lon_diff\n",
    "    features[DISTANCE_COLUMN] = dist\n",
    "    date_time = features['pickupdate']\n",
    "    date_time = tf.py_func(pd_date_time, [date_time], [tf.int32]*5)\n",
    "    features[DATE_COLUMNS[0]] = date_time[0]\n",
    "    features[DATE_COLUMNS[1]] = date_time[1]\n",
    "    features[DATE_COLUMNS[2]] = date_time[2]\n",
    "    features[DATE_COLUMNS[3]] = date_time[3]\n",
    "    features[DATE_COLUMNS[4]] = date_time[4]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Sq2-ypEma9C"
   },
   "source": [
    "Create input function to load data into datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o62hXFkpma9D"
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "    def _input_fun():\n",
    "        def parse_csv(file_data):\n",
    "            columns = tf.decode_csv(file_data, DEFAULTS)\n",
    "            features = dict( zip(CSV_COLUMNS, columns))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return feature_engg(features), label\n",
    "        \n",
    "        dataset = tf.data.TextLineDataset(filename).skip(1).map(parse_csv)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1\n",
    "        \n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        \n",
    "        batch_features, batch_labels = dataset.make_one_shot_iterator().get_next()\n",
    "        \n",
    "        return batch_features, batch_labels\n",
    "    \n",
    "    return _input_fun\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4jmFwwcma9O"
   },
   "source": [
    "These are the raw input columns, and will be provided for prediction also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwyPM5zFma9P"
   },
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    # Define features\n",
    "    tf.feature_column.categorical_column_with_identity('month', num_buckets = 12),\n",
    "    tf.feature_column.categorical_column_with_identity('day', num_buckets = 31),\n",
    "    tf.feature_column.categorical_column_with_identity('day_of_week', num_buckets = 7),\n",
    "    tf.feature_column.categorical_column_with_identity('hours', num_buckets = 24),\n",
    "\n",
    "    # Numeric columns\n",
    "    tf.feature_column.numeric_column('pickuplat'),\n",
    "    tf.feature_column.numeric_column('pickuplon'),\n",
    "    tf.feature_column.numeric_column('dropofflat'),\n",
    "    tf.feature_column.numeric_column('dropofflon'),\n",
    "    tf.feature_column.numeric_column('passengers'),\n",
    "    \n",
    "    # Engineered features that are created in the input_fn\n",
    "    tf.feature_column.numeric_column('latitude_diff'),\n",
    "    tf.feature_column.numeric_column('longitude_diff'),\n",
    "    tf.feature_column.numeric_column('euclid_distance')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnDPsd5qma9S"
   },
   "source": [
    "Build the wide-n-deep regressor estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mFSRxmMma9U"
   },
   "outputs": [],
   "source": [
    "def build_estimator(model_dir, nbuckets, hidden_units):\n",
    "    \n",
    "    # Input columns\n",
    "    (month, days, dayofweek, hourofday, plat, plon, dlat, dlon, pcount, latdiff, londiff, euclidean) = INPUT_COLUMNS\n",
    "    \n",
    "    # Bucketize the lats & lons\n",
    "    latbuckets = np.linspace(38.0, 42.0, nbuckets).tolist()\n",
    "    lonbuckets = np.linspace(-76.0, -72.0, nbuckets).tolist()\n",
    "    b_plat = tf.feature_column.bucketized_column(plat, latbuckets)\n",
    "    b_dlat = tf.feature_column.bucketized_column(dlat, latbuckets)\n",
    "    b_plon = tf.feature_column.bucketized_column(plon, lonbuckets)\n",
    "    b_dlon = tf.feature_column.bucketized_column(dlon, lonbuckets)\n",
    "    \n",
    "    # Feature cross\n",
    "    ploc = tf.feature_column.crossed_column([b_plat, b_plon], nbuckets * nbuckets)\n",
    "    dloc = tf.feature_column.crossed_column([b_dlat, b_dlon], nbuckets * nbuckets)\n",
    "    pd_pair = tf.feature_column.crossed_column([ploc, dloc], nbuckets ** 4 )\n",
    "    day_hr =  tf.feature_column.crossed_column([dayofweek, hourofday], 24 * 7)\n",
    "    #month_day = tf.feature_column.crossed_column([month, days], 12 * 31)\n",
    "    \n",
    "    # Wide columns and deep columns.\n",
    "    wide_columns = [\n",
    "        # Feature crosses\n",
    "        dloc, ploc, pd_pair,\n",
    "        day_hr,\n",
    "        #month_day,\n",
    "        # Sparse columns\n",
    "        dayofweek, hourofday,\n",
    "        # Anything with a linear relationship\n",
    "        pcount \n",
    "    ]\n",
    "    deep_columns = [\n",
    "        # Embedding_column to \"group\" together ...\n",
    "        tf.feature_column.embedding_column(pd_pair, 10),\n",
    "        tf.feature_column.embedding_column(day_hr, 10),\n",
    "        #tf.feature_column.embedding_column(month_day, 10),\n",
    "        # Numeric columns\n",
    "        plat, plon, dlat, dlon,\n",
    "        latdiff, londiff, euclidean\n",
    "    ]\n",
    "    \n",
    "    estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "        model_dir = model_dir,\n",
    "        linear_feature_columns = wide_columns,\n",
    "        dnn_feature_columns = deep_columns,\n",
    "        dnn_hidden_units = hidden_units,\n",
    "        dnn_optimizer='Adagrad',\n",
    "    )\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5jsSxd8ma9X"
   },
   "source": [
    "Variables for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiHxoKE4ma9Z"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "HEADER_COLS = 1\n",
    "MAX_STEPS = 10000\n",
    "NBBUCKETS = 10\n",
    "HIDDEN_UNITS = [128, 32, 4]\n",
    "MODEL_DIR = 'C:\\\\Rajesh\\\\training\\\\2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "hNJ34wBKma9c",
    "outputId": "3102bd55-6589-4544-ee77-5ad433b50b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Rajesh\\\\training\\\\2\\\\', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000000015DB3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = None\n",
    "estimator = build_estimator(MODEL_DIR, NBBUCKETS, HIDDEN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "koJ2Q6YOma9n",
    "outputId": "f7133b7a-f361-4e94-c184-13808bf10659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Rajesh\\training\\2\\model.ckpt.\n",
      "INFO:tensorflow:loss = 100908.36, step = 1\n",
      "INFO:tensorflow:global_step/sec: 4.08347\n",
      "INFO:tensorflow:loss = 61837.168, step = 101 (24.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.08347\n",
      "INFO:tensorflow:loss = 60332.18, step = 201 (24.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.56519\n",
      "INFO:tensorflow:loss = 35727.37, step = 301 (28.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23012\n",
      "INFO:tensorflow:loss = 52157.523, step = 401 (23.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.18725\n",
      "INFO:tensorflow:loss = 45459.047, step = 501 (23.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42008\n",
      "INFO:tensorflow:loss = 36842.668, step = 601 (22.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.1088\n",
      "INFO:tensorflow:loss = 55743.47, step = 701 (24.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26967\n",
      "INFO:tensorflow:loss = 71007.89, step = 801 (23.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23227\n",
      "INFO:tensorflow:loss = 33914.434, step = 901 (23.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36491\n",
      "INFO:tensorflow:loss = 51019.203, step = 1001 (22.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.57561\n",
      "INFO:tensorflow:loss = 43038.05, step = 1101 (21.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42556\n",
      "INFO:tensorflow:loss = 46766.324, step = 1201 (22.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.0458\n",
      "INFO:tensorflow:loss = 42299.906, step = 1301 (24.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3465\n",
      "INFO:tensorflow:loss = 40659.812, step = 1401 (23.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29221\n",
      "INFO:tensorflow:loss = 78386.24, step = 1501 (23.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.56892\n",
      "INFO:tensorflow:loss = 38485.76, step = 1601 (21.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.54587\n",
      "INFO:tensorflow:loss = 39315.89, step = 1701 (22.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42302\n",
      "INFO:tensorflow:loss = 50592.805, step = 1801 (22.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.57457\n",
      "INFO:tensorflow:loss = 38459.383, step = 1901 (21.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.53679\n",
      "INFO:tensorflow:loss = 36585.133, step = 2001 (22.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.55747\n",
      "INFO:tensorflow:loss = 67633.67, step = 2101 (21.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.59664\n",
      "INFO:tensorflow:loss = 52785.375, step = 2201 (21.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26694\n",
      "INFO:tensorflow:loss = 45718.47, step = 2301 (23.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17624\n",
      "INFO:tensorflow:loss = 52851.625, step = 2401 (23.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.53762\n",
      "INFO:tensorflow:loss = 39416.824, step = 2501 (22.038 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2577 into C:\\Rajesh\\training\\2\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.52059\n",
      "INFO:tensorflow:loss = 54490.848, step = 2601 (22.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48551\n",
      "INFO:tensorflow:loss = 51794.992, step = 2701 (22.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27168\n",
      "INFO:tensorflow:loss = 35951.625, step = 2801 (23.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.42971\n",
      "INFO:tensorflow:loss = 43223.914, step = 2901 (29.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.50054\n",
      "INFO:tensorflow:loss = 44814.824, step = 3001 (28.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26421\n",
      "INFO:tensorflow:loss = 52115.887, step = 3101 (23.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37828\n",
      "INFO:tensorflow:loss = 551644.7, step = 3201 (22.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36491\n",
      "INFO:tensorflow:loss = 42977.047, step = 3301 (22.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29923\n",
      "INFO:tensorflow:loss = 46683.99, step = 3401 (23.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.53332\n",
      "INFO:tensorflow:loss = 41529.215, step = 3501 (28.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.66046\n",
      "INFO:tensorflow:loss = 84930.62, step = 3601 (27.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22476\n",
      "INFO:tensorflow:loss = 44288.465, step = 3701 (23.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.06091\n",
      "INFO:tensorflow:loss = 56081.836, step = 3801 (24.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35559\n",
      "INFO:tensorflow:loss = 46047.984, step = 3901 (22.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.45853\n",
      "INFO:tensorflow:loss = 31005.479, step = 4001 (28.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98045\n",
      "INFO:tensorflow:loss = 37932.523, step = 4101 (33.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.54786\n",
      "INFO:tensorflow:loss = 49061.688, step = 4201 (28.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.02204\n",
      "INFO:tensorflow:loss = 40249.65, step = 4301 (24.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17206\n",
      "INFO:tensorflow:loss = 33275.0, step = 4401 (23.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3448\n",
      "INFO:tensorflow:loss = 43667.863, step = 4501 (23.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52755\n",
      "INFO:tensorflow:loss = 46131.617, step = 4601 (22.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.18831\n",
      "INFO:tensorflow:loss = 37454.547, step = 4701 (23.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.56455\n",
      "INFO:tensorflow:loss = 97661.266, step = 4801 (28.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.15628\n",
      "INFO:tensorflow:loss = 35281.195, step = 4901 (24.063 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4950 into C:\\Rajesh\\training\\2\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.30571\n",
      "INFO:tensorflow:loss = 38706.945, step = 5001 (23.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35294\n",
      "INFO:tensorflow:loss = 35689.47, step = 5101 (22.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.68541\n",
      "INFO:tensorflow:loss = 40738.74, step = 5201 (27.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.94089\n",
      "INFO:tensorflow:loss = 49593.754, step = 5301 (25.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76946\n",
      "INFO:tensorflow:loss = 25152.234, step = 5401 (26.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26185\n",
      "INFO:tensorflow:loss = 35280.37, step = 5501 (23.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.66797\n",
      "INFO:tensorflow:loss = 48772.027, step = 5601 (27.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.52342\n",
      "INFO:tensorflow:loss = 41092.305, step = 5701 (28.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.44936\n",
      "INFO:tensorflow:loss = 45523.5, step = 5801 (28.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.88462\n",
      "INFO:tensorflow:loss = 41098.242, step = 5901 (25.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.31839\n",
      "INFO:tensorflow:loss = 31066.734, step = 6001 (43.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.09644\n",
      "INFO:tensorflow:loss = 32685.988, step = 6101 (24.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.11939\n",
      "INFO:tensorflow:loss = 38072.03, step = 6201 (24.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.97875\n",
      "INFO:tensorflow:loss = 43907.203, step = 6301 (25.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.9843\n",
      "INFO:tensorflow:loss = 72502.63, step = 6401 (25.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.59896\n",
      "INFO:tensorflow:loss = 40482.78, step = 6501 (27.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26106\n",
      "INFO:tensorflow:loss = 53865.22, step = 6601 (23.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45648\n",
      "INFO:tensorflow:loss = 39376.406, step = 6701 (22.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29271\n",
      "INFO:tensorflow:loss = 40117.668, step = 6801 (23.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2059\n",
      "INFO:tensorflow:loss = 35265.93, step = 6901 (23.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37905\n",
      "INFO:tensorflow:loss = 35332.938, step = 7001 (22.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.38231\n",
      "INFO:tensorflow:loss = 47789.707, step = 7101 (22.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48511\n",
      "INFO:tensorflow:loss = 42543.492, step = 7201 (22.296 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7296 into C:\\Rajesh\\training\\2\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.34216\n",
      "INFO:tensorflow:loss = 26371.125, step = 7301 (23.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31239\n",
      "INFO:tensorflow:loss = 61334.938, step = 7401 (23.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52202\n",
      "INFO:tensorflow:loss = 36154.08, step = 7501 (22.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41716\n",
      "INFO:tensorflow:loss = 40198.047, step = 7601 (22.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36890.555, step = 7701 (22.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43833\n",
      "INFO:tensorflow:loss = 34062.15, step = 7801 (22.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4403\n",
      "INFO:tensorflow:loss = 28230.3, step = 7901 (22.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51141\n",
      "INFO:tensorflow:loss = 38830.016, step = 8001 (22.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48129\n",
      "INFO:tensorflow:loss = 39847.04, step = 8101 (22.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.39445\n",
      "INFO:tensorflow:loss = 30719.443, step = 8201 (22.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45395\n",
      "INFO:tensorflow:loss = 35645.344, step = 8301 (22.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47527\n",
      "INFO:tensorflow:loss = 34660.82, step = 8401 (22.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35673\n",
      "INFO:tensorflow:loss = 47399.6, step = 8501 (22.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.54401\n",
      "INFO:tensorflow:loss = 28916.29, step = 8601 (22.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40723\n",
      "INFO:tensorflow:loss = 56427.89, step = 8701 (22.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40451\n",
      "INFO:tensorflow:loss = 45283.816, step = 8801 (22.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45573\n",
      "INFO:tensorflow:loss = 42948.773, step = 8901 (22.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43086\n",
      "INFO:tensorflow:loss = 43301.87, step = 9001 (22.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.14422\n",
      "INFO:tensorflow:loss = 40464.43, step = 9101 (24.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84986\n",
      "INFO:tensorflow:loss = 71060.79, step = 9201 (25.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17484\n",
      "INFO:tensorflow:loss = 27430.646, step = 9301 (23.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32339\n",
      "INFO:tensorflow:loss = 22935.484, step = 9401 (23.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.06802\n",
      "INFO:tensorflow:loss = 39061.305, step = 9501 (24.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27716\n",
      "INFO:tensorflow:loss = 32471.883, step = 9601 (23.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41423\n",
      "INFO:tensorflow:loss = 38823.547, step = 9701 (22.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52039\n",
      "INFO:tensorflow:loss = 36758.523, step = 9801 (22.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36148\n",
      "INFO:tensorflow:loss = 61056.355, step = 9901 (22.933 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9912 into C:\\Rajesh\\training\\2\\model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Rajesh\\training\\2\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 39023.227.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedRegressor at 0x15db3e48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn = read_dataset(\n",
    "                            filename = FILE_NAME,\n",
    "                            mode = tf.estimator.ModeKeys.TRAIN,\n",
    "                            batch_size = BATCH_SIZE), \n",
    "                max_steps = MAX_STEPS\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE_NAME = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXsszocuma9s"
   },
   "outputs": [],
   "source": [
    "predictions = estimator.predict(input_fn = read_dataset(\n",
    "                                            filename = TEST_FILE_NAME,\n",
    "                                            mode = tf.estimator.ModeKeys.PREDICT,\n",
    "                                            batch_size = BATCH_SIZE)\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Rajesh\\training\\2\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predict_df = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[10.746673]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10.745453]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10.335909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[10.252174]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[10.255049]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions\n",
       "0  [10.746673]\n",
       "1  [10.745453]\n",
       "2  [10.335909]\n",
       "3  [10.252174]\n",
       "4  [10.255049]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df_cleaned = pd.DataFrame(predict_df['predictions'].apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.746673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.745453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.335909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.252174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.255049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions\n",
       "0    10.746673\n",
       "1    10.745453\n",
       "2    10.335909\n",
       "3    10.252174\n",
       "4    10.255049"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions    11.296935\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_cleaned.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions    2.457245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_cleaned.std()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NYC Taxi regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
